---
phase: 05-audio-integration
plan: 01
type: execute
---

<objective>
Create AudioManager service with 3-channel audio system (music, voice, effects) and voice ducking.

Purpose: Establish the audio infrastructure that all voice lines, music, and sound effects will use.
Output: Working AudioManager with independent volume controls, voice ducking, and queue system.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

**Prior work:**
@.planning/phases/04-reward-system/04-03-SUMMARY.md

**Key files:**
@BennieGame/BennieGame/App/BennieGameApp.swift
@BennieGame/BennieGame/App/AppCoordinator.swift

**Tech stack:**
- AVFoundation (built into iOS) for audio playback
- @Observable pattern for state management
- SwiftUI environment injection

**Audio requirements (from PLAYBOOK):**
- 3 independent channels: Music (30% default), Voice (100%), Effects (70%)
- Voice ducking: Music volume drops to 15% during voice playback, restores after
- Voice queue: Sequential voice lines play one after another
- Mute control: Single toggle affects all channels
- Graceful degradation: Missing audio files don't crash, log warning
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AudioManager service with 3-channel architecture</name>
  <files>BennieGame/BennieGame/Core/Services/AudioManager.swift, BennieGame.xcodeproj/project.pbxproj</files>
  <action>
Create AudioManager.swift as an @Observable class:

```swift
import AVFoundation

@Observable
class AudioManager {
    // MARK: - Audio Players
    private var musicPlayer: AVAudioPlayer?
    private var voicePlayer: AVAudioPlayer?
    private var effectsPlayer: AVAudioPlayer?

    // MARK: - Volume Controls
    var musicVolume: Float = 0.30 { didSet { musicPlayer?.volume = isMuted ? 0 : musicVolume } }
    var voiceVolume: Float = 1.00 { didSet { voicePlayer?.volume = isMuted ? 0 : voiceVolume } }
    var effectsVolume: Float = 0.70 { didSet { effectsPlayer?.volume = isMuted ? 0 : effectsVolume } }

    // MARK: - State
    var isMuted: Bool = false { didSet { updateAllVolumes() } }
    private var isVoicePlaying: Bool = false
    private var preDuckMusicVolume: Float = 0.30

    // MARK: - Voice Queue
    private var voiceQueue: [String] = []

    // MARK: - Public Methods
    func playMusic(_ filename: String, loop: Bool = true)
    func playVoice(_ filename: String, completion: (() -> Void)? = nil)
    func playEffect(_ filename: String)
    func stopMusic()
    func stopAll()
    func toggleMute()

    // MARK: - Private Helpers
    private func updateAllVolumes()
    private func duckMusic()
    private func restoreMusic()
    private func playNextInQueue()
    private func loadAudioFile(_ filename: String, type: String = "aac") -> AVAudioPlayer?
}
```

Implementation requirements:
- Use AVAudioPlayer for each channel
- loadAudioFile should use Bundle.main.url(forResource:withExtension:)
- If file not found, print warning and return nil (graceful degradation)
- Voice ducking: When playVoice() called, save current musicVolume to preDuckMusicVolume, set musicPlayer?.volume to 0.15
- Voice restore: When voice finishes (AVAudioPlayerDelegate), restore musicPlayer?.volume to preDuckMusicVolume
- Queue system: If voice already playing when playVoice() called, append to voiceQueue array
- On voice completion, check voiceQueue and playNextInQueue() if not empty
- Audio session: Configure AVAudioSession.sharedInstance() for .playback category in init

Add file to Xcode project.pbxproj.
  </action>
  <verify>xcodebuild build succeeds, AudioManager compiles without errors</verify>
  <done>AudioManager service created with 3 channels, voice ducking, and queue system</done>
</task>

<task type="auto">
  <name>Task 2: Create audio file directory structure and placeholder audio</name>
  <files>BennieGame/BennieGame/Resources/Audio/</files>
  <action>
Create the audio directory structure for organizing audio files:

Directory structure:
```
BennieGame/BennieGame/Resources/Audio/
├── Music/
│   └── (placeholder for forest_ambient.aac)
├── Voice/
│   ├── Narrator/
│   │   └── (placeholder voice files)
│   └── Bennie/
│       └── (placeholder voice files)
└── Effects/
    └── (placeholder effect files)
```

For MVP, create text placeholder files explaining what audio goes where:
- Audio/README.md with structure explanation
- No actual .aac files needed yet (Phase 10 asset production)

The AudioManager will gracefully handle missing files.

Create folder structure using Bash mkdir commands. Add the Audio folder reference to the Xcode project.
  </action>
  <verify>Directory structure exists, README.md explains audio organization</verify>
  <done>Audio directory structure created with organization for music/voice/effects</done>
</task>

<task type="auto">
  <name>Task 3: Inject AudioManager into app environment</name>
  <files>BennieGame/BennieGame/App/BennieGameApp.swift</files>
  <action>
Update BennieGameApp.swift to create and inject AudioManager:

1. Add property: `@State private var audioManager = AudioManager()`
2. Inject into environment: `.environment(audioManager)`
3. AudioManager should be shared across all views

The AudioManager will now be accessible via `@Environment(AudioManager.self)` in any view.

Do NOT add audio triggers to views yet - that's Plan 05-03.
  </action>
  <verify>xcodebuild build succeeds, AudioManager is in environment</verify>
  <done>AudioManager injected into app environment, accessible throughout app</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] xcodebuild build succeeds without errors
- [ ] AudioManager.swift exists in Core/Services/
- [ ] Audio directory structure created
- [ ] AudioManager injected in BennieGameApp
- [ ] No crashes when playing audio (graceful degradation for missing files)
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- AudioManager has 3 independent channels
- Voice ducking implemented (music 30% → 15% during voice)
- Voice queue system works
- Mute toggle affects all channels
- Ready for voice/effect integration
</success_criteria>

<output>
After completion, create `.planning/phases/05-audio-integration/05-01-SUMMARY.md` with:
- AudioManager architecture summary
- Files created
- Voice ducking implementation
- Any issues with AVFoundation setup
</output>
